import torch
import asyncio
from orpheus_tts import OrpheusModel
import wave
import time
async def test_streaming_with_timestamps():
   # model = OrpheusModel(model_name="canopylabs/3b-hi-ft-research_release")
   model = OrpheusModel(model_name="./OrpheusTTS/checkpoints",  #PATH TO THE CHECKPOINTS
                        # dtype = "half" #torch.float16
                        )
   await model.ensure_warm() #warmup here
    
   '''
   Prompt is the text field  
   '''
   prompt ='''Delhi ‡§ï‡•Ä ‡§è‡§ï retail chain ‡§®‡•á ‡§π‡§Æ‡§æ‡§∞‡•á solutions ‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä sales ‡§Æ‡•á‡§Ç 
   30 percent ‡§§‡§ï increase ‡§¶‡•á‡§ñ‡•Ä ‡§π‡•à, 
   <hmm..> ‡§â‡§®‡§ï‡§æ feedback ‡§¨‡§π‡•Å‡§§ encouraging ‡§∞‡§π‡§æ ‡§π‡•à|
   '''
    
   start_time = time.monotonic()
   first_chunk_time = None
   
   with wave.open("output_hindi.wav", "wb") as wf:
      wf.setnchannels(1)
      wf.setsampwidth(2)
      wf.setframerate(24000)
      
      chunk_counter = 0
      
      async for audio_chunk in model.generate_speech_async(
         prompt=prompt,
         voice=None
      ):
         chunk_counter += 1
         current_time = time.monotonic() - start_time
         
         # Record time to first chunk (TTFB)
         if first_chunk_time is None:
               first_chunk_time = current_time
               print(f"‚ö° First chunk received at: {first_chunk_time:.3f}s")
         
         chunk_size = len(audio_chunk)
         print(f"Chunk {chunk_counter}: {chunk_size} bytes at {current_time:.3f}s")
         wf.writeframes(audio_chunk)
      
      total_time = time.monotonic() - start_time
      print(f"\nüìä Time to first byte: {first_chunk_time:.3f}s")
      print(f"üìä Total generation time: {total_time:.3f}s")

asyncio.run(test_streaming_with_timestamps())

from orpheus_tts import OrpheusModel
import wave
import time

model = OrpheusModel(model_name ="SachinTelecmi/Orpheus-tts-hi", max_model_len=1024)
prompt = '''‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤! ‡§π‡§Æ‡§æ‡§∞‡§æ CRM software businesses ‡§ï‡•ã leads manage ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ï‡§ø ‡§Ø‡•á software ‡§Ü‡§™‡§ï‡•á business ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•à‡§∏‡•á ‡§´‡§æ‡§Ø‡§¶‡•á‡§Æ‡§Ç‡§¶ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?'''

start_time = time.monotonic()
syn_tokens = model.generate_speech_audio(
   prompt=prompt,
   ref_text = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§∞‡§æ‡§ï‡•á‡§∂ ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å <happy> How can I assist you today?",
   voice_path = "/home/user/voice/Orpheus-TTS/finetune/hf_cache/datasets--telecmiusa--tts-hi-data/snapshots/d564239b4542d4e25ee213660bf0104e700858ac/SPEECHRIV/1_AGENT.wav",
   voice=None,
   )

with wave.open("output_hi_23.wav", "wb") as wf:
         wf.setnchannels(1)
         wf.setsampwidth(2)
         wf.setframerate(24000)
         
         chunk_counter = 0
         
         async for audio_chunk in model.generate_speech_async(
            prompt=prompt,
         ):
            chunk_counter += 1
            current_time = time.monotonic() - start_time
            
            # Record time to first chunk (TTFB)
            if first_chunk_time is None:
                  first_chunk_time = current_time
                  print(f"‚ö° First chunk received at: {first_chunk_time:.3f}s")
            
            chunk_size = len(audio_chunk)
            print(f"Chunk {chunk_counter}: {chunk_size} bytes at {current_time:.3f}s")
            wf.writeframes(audio_chunk)
         
         total_time = time.monotonic() - start_time
         print(f"\nüìä Time to first byte: {first_chunk_time:.3f}s")
         print(f"üìä Total generation time: {total_time:.3f}s")




# CLONING
# import torch
# import asyncio
# from orpheus_tts import OrpheusModel
# import wave
# import time
# async def test_streaming_with_timestamps():
#    # model = OrpheusModel(model_name="canopylabs/3b-hi-ft-research_release")
#    model = OrpheusModel(model_name ="SachinTelecmi/Orpheus-tts-hi", max_model_len=1024)
#    prompt = '''‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤! ‡§π‡§Æ‡§æ‡§∞‡§æ CRM software businesses ‡§ï‡•ã leads manage ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ï‡§ø ‡§Ø‡•á software ‡§Ü‡§™‡§ï‡•á business ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•à‡§∏‡•á ‡§´‡§æ‡§Ø‡§¶‡•á‡§Æ‡§Ç‡§¶ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?'''

#    # await model.ensure_warm() #warmup here
    
#    # '''
#    # Prompt is the text field  
#    # '''
#    # prompt ='''Delhi ‡§ï‡•Ä ‡§è‡§ï retail chain ‡§®‡•á ‡§π‡§Æ‡§æ‡§∞‡•á solutions ‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä sales ‡§Æ‡•á‡§Ç, 30 percent ‡§§‡§ï increase ‡§¶‡•á‡§ñ‡•Ä ‡§π‡•à, <hmm..> ‡§â‡§®‡§ï‡§æ feedback ‡§¨‡§π‡•Å‡§§ encouraging ‡§∞‡§π‡§æ ‡§π‡•à|
#    # '''
    
#    start_time = time.monotonic()
#    first_chunk_time = None
   
#    with wave.open("output_hi.wav", "wb") as wf:
#       wf.setnchannels(1)
#       wf.setsampwidth(2)
#       wf.setframerate(24000)
      
#       chunk_counter = 0
      
#       async for audio_chunk in model.generate_speech_async(
#          prompt=prompt,
#          ref_text = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§∞‡§æ‡§ï‡•á‡§∂ ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å <happy> How can I assist you today?",
#          voice_path = "/home/user/voice/Orpheus-TTS/finetune/hf_cache/datasets--telecmiusa--tts-hi-data/snapshots/d564239b4542d4e25ee213660bf0104e700858ac/SPEECHRIV/1_AGENT.wav",
#          voice=None,

#       ):
#          chunk_counter += 1
#          current_time = time.monotonic() - start_time
         
#          # Record time to first chunk (TTFB)
#          if first_chunk_time is None:
#                first_chunk_time = current_time
#                print(f"‚ö° First chunk received at: {first_chunk_time:.3f}s")
         
#          chunk_size = len(audio_chunk)
#          print(f"Chunk {chunk_counter}: {chunk_size} bytes at {current_time:.3f}s")
#          wf.writeframes(audio_chunk)
      
#       total_time = time.monotonic() - start_time
#       print(f"\nüìä Time to first byte: {first_chunk_time:.3f}s")
#       print(f"üìä Total generation time: {total_time:.3f}s")

# asyncio.run(test_streaming_with_timestamps())
