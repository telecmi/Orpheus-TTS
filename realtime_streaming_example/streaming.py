import torch
import asyncio
from orpheus_tts import OrpheusModel
import wave
import time
async def test_streaming_with_timestamps():
   # model = OrpheusModel(model_name="canopylabs/3b-hi-ft-research_release")
   model = OrpheusModel(model_name="./OrpheusTTS/checkpoints",  #PATH TO THE CHECKPOINTS
                        # dtype = "half" #torch.float16
                        )
   await model.ensure_warm() #warmup here
    
   '''
   Prompt is the text field  
   '''
   prompt ='''Delhi ‡§ï‡•Ä ‡§è‡§ï retail chain ‡§®‡•á ‡§π‡§Æ‡§æ‡§∞‡•á solutions ‡§∏‡•á ‡§Ö‡§™‡§®‡•Ä sales ‡§Æ‡•á‡§Ç 
   30 percent ‡§§‡§ï increase ‡§¶‡•á‡§ñ‡•Ä ‡§π‡•à, 
   <hmm..> ‡§â‡§®‡§ï‡§æ feedback ‡§¨‡§π‡•Å‡§§ encouraging ‡§∞‡§π‡§æ ‡§π‡•à|
   '''
    
   start_time = time.monotonic()
   first_chunk_time = None
   
   with wave.open("output_hindi.wav", "wb") as wf:
      wf.setnchannels(1)
      wf.setsampwidth(2)
      wf.setframerate(24000)
      
      chunk_counter = 0
      
      async for audio_chunk in model.generate_speech_async(
         prompt=prompt,
         voice=None
      ):
         chunk_counter += 1
         current_time = time.monotonic() - start_time
         
         # Record time to first chunk (TTFB)
         if first_chunk_time is None:
               first_chunk_time = current_time
               print(f"‚ö° First chunk received at: {first_chunk_time:.3f}s")
         
         chunk_size = len(audio_chunk)
         print(f"Chunk {chunk_counter}: {chunk_size} bytes at {current_time:.3f}s")
         wf.writeframes(audio_chunk)
      
      total_time = time.monotonic() - start_time
      print(f"\nüìä Time to first byte: {first_chunk_time:.3f}s")
      print(f"üìä Total generation time: {total_time:.3f}s")

asyncio.run(test_streaming_with_timestamps())